{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import gensim\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from time import time\n",
    "from typing import List, Dict, Set, Tuple\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import gensim\n",
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from pandas_profiling import ProfileReport\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\n",
      "���������ļ���\n"
     ]
    }
   ],
   "source": [
    "!wget http://recsys.cau.ac.kr:8095/wiki_300_5_word2vec.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_892916/3006279208.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodelwo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'wiki_300_5_word2vec.bin'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[0;32m   1627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1628\u001b[0m         \"\"\"\n\u001b[1;32m-> 1629\u001b[1;33m         return _load_word2vec_format(\n\u001b[0m\u001b[0;32m   1630\u001b[0m             \u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1631\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno_header\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mno_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[0;32m   1970\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1971\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1972\u001b[1;33m             _word2vec_read_binary(\n\u001b[0m\u001b[0;32m   1973\u001b[0m                 \u001b[0mfin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_chunk_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1974\u001b[0m             )\n",
      "\u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m_word2vec_read_binary\u001b[1;34m(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, binary_chunk_size)\u001b[0m\n\u001b[0;32m   1865\u001b[0m         \u001b[0mnew_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinary_chunk_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[0mchunk\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnew_chunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         processed_words, chunk = _add_bytes_to_kv(\n\u001b[0m\u001b[0;32m   1868\u001b[0m             kv, counts, chunk, vocab_size, vector_size, datatype, unicode_errors)\n\u001b[0;32m   1869\u001b[0m         \u001b[0mtot_processed_words\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mprocessed_words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m_add_bytes_to_kv\u001b[1;34m(kv, counts, chunk, vocab_size, vector_size, datatype, unicode_errors)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mword\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m         \u001b[0mvector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfrombuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi_vector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mREAL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0m_add_word_to_kv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi_vector\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbytes_per_vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m         \u001b[0mprocessed_words\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m_add_word_to_kv\u001b[1;34m(kv, counts, word, weights, vocab_size)\u001b[0m\n\u001b[0;32m   1819\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"duplicate word '%s' in word2vec file, ignoring all but first\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1820\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1821\u001b[1;33m     \u001b[0mword_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1822\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1823\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcounts\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36madd_vector\u001b[1;34m(self, key, vector)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_to_key\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget_index\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey_to_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget_index\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_index\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtarget_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "modelwo = gensim.models.KeyedVectors.load_word2vec_format(r'wiki_300_5_word2vec.bin',binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>word</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "      <th>S5</th>\n",
       "      <th>S6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>백신패스</td>\n",
       "      <td>vaccine</td>\n",
       "      <td>inoculation</td>\n",
       "      <td>admit</td>\n",
       "      <td>epidemic</td>\n",
       "      <td>force</td>\n",
       "      <td>certification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>위드코로나</td>\n",
       "      <td>normalize</td>\n",
       "      <td>recuperation</td>\n",
       "      <td>coexistence</td>\n",
       "      <td>vaccine</td>\n",
       "      <td>inoculation</td>\n",
       "      <td>infection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>접종완료자</td>\n",
       "      <td>vaccine</td>\n",
       "      <td>inoculation</td>\n",
       "      <td>completion</td>\n",
       "      <td>effect</td>\n",
       "      <td>entry</td>\n",
       "      <td>death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ウィズコロナ</td>\n",
       "      <td>recuperation</td>\n",
       "      <td>coexistence</td>\n",
       "      <td>vaccine</td>\n",
       "      <td>inoculation</td>\n",
       "      <td>Normalize</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>段階日常回復</td>\n",
       "      <td>stage</td>\n",
       "      <td>recuperation</td>\n",
       "      <td>daily</td>\n",
       "      <td>state</td>\n",
       "      <td>coexistence</td>\n",
       "      <td>virus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>112</td>\n",
       "      <td>SBN</td>\n",
       "      <td>senior</td>\n",
       "      <td>artist</td>\n",
       "      <td>work</td>\n",
       "      <td>study</td>\n",
       "      <td>university</td>\n",
       "      <td>brother</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>113</td>\n",
       "      <td>黙トレ</td>\n",
       "      <td>posted</td>\n",
       "      <td>gym</td>\n",
       "      <td>cluster</td>\n",
       "      <td>occurred</td>\n",
       "      <td>early</td>\n",
       "      <td>stages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>114</td>\n",
       "      <td>ウェビナー</td>\n",
       "      <td>web</td>\n",
       "      <td>seminar</td>\n",
       "      <td>internet</td>\n",
       "      <td>meeting</td>\n",
       "      <td>online</td>\n",
       "      <td>speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>115</td>\n",
       "      <td>당모치</td>\n",
       "      <td>every</td>\n",
       "      <td>chicken</td>\n",
       "      <td>right</td>\n",
       "      <td>as</td>\n",
       "      <td>food</td>\n",
       "      <td>choice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>116</td>\n",
       "      <td>쪄죽따</td>\n",
       "      <td>americano</td>\n",
       "      <td>warm</td>\n",
       "      <td>even</td>\n",
       "      <td>steam</td>\n",
       "      <td>water</td>\n",
       "      <td>drink</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       K    word            S1            S2           S3           S4  \\\n",
       "0      1    백신패스       vaccine   inoculation        admit     epidemic   \n",
       "1      2   위드코로나     normalize  recuperation  coexistence      vaccine   \n",
       "2      3   접종완료자       vaccine   inoculation   completion       effect   \n",
       "3      4  ウィズコロナ  recuperation   coexistence      vaccine  inoculation   \n",
       "4      5  段階日常回復         stage  recuperation        daily        state   \n",
       "..   ...     ...           ...           ...          ...          ...   \n",
       "111  112     SBN        senior        artist         work        study   \n",
       "112  113     黙トレ        posted           gym      cluster     occurred   \n",
       "113  114   ウェビナー           web       seminar     internet      meeting   \n",
       "114  115     당모치         every       chicken        right           as   \n",
       "115  116     쪄죽따     americano          warm         even        steam   \n",
       "\n",
       "              S5             S6  \n",
       "0          force  certification  \n",
       "1    inoculation      infection  \n",
       "2          entry          death  \n",
       "3      Normalize          state  \n",
       "4    coexistence          virus  \n",
       "..           ...            ...  \n",
       "111   university        brother  \n",
       "112        early         stages  \n",
       "113       online         speech  \n",
       "114         food         choice  \n",
       "115        water          drink  \n",
       "\n",
       "[116 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attrition = 'test.csv'\n",
    "df_ac = pd.read_csv(attrition,encoding='utf-8')\n",
    "df_ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'modelwo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_892916/1693044867.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mV\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m116\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0ma1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelwo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_ac\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_ac\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'K'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'S1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0ma2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelwo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_ac\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_ac\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'K'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'S2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0ma3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelwo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_ac\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_ac\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'K'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'S3'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0ma4\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelwo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_ac\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_ac\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'K'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'S4'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'modelwo' is not defined"
     ]
    }
   ],
   "source": [
    "V=116\n",
    "a1=list(modelwo[df_ac.loc[df_ac['K']==V]['S1'].values[0]].ravel())\n",
    "a2=list(modelwo[df_ac.loc[df_ac['K']==V]['S2'].values[0]].ravel())\n",
    "a3=list(modelwo[df_ac.loc[df_ac['K']==V]['S3'].values[0]].ravel())\n",
    "a4=list(modelwo[df_ac.loc[df_ac['K']==V]['S4'].values[0]].ravel())\n",
    "a5=list(modelwo[df_ac.loc[df_ac['K']==V]['S5'].values[0]].ravel())\n",
    "a6=list(modelwo[df_ac.loc[df_ac['K']==V]['S6'].values[0]].ravel())\n",
    "df_pc=str(a1)+'|'+str(a2)+'|'+str(a3)+'|'+str(a4)+'|'+str(a5)+'|'+str(a6)\n",
    "f = open(\"model_Weight.txt\",'w') \n",
    "f.write(df_pc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "from time import time\n",
    "from typing import List, Dict, Set, Tuple\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import gensim\n",
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from pandas_profiling import ProfileReport\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "      <th>S5</th>\n",
       "      <th>S6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.08547448, -0.29826584, -0.14741431, -0.6706...</td>\n",
       "      <td>-0.2249016, -0.053476267, 0.08432953, -0.04551...</td>\n",
       "      <td>0.20120747, -0.40818706, 0.06754328, -0.208118...</td>\n",
       "      <td>-0.04608272, -0.38059863, -0.3007064, -0.10318...</td>\n",
       "      <td>-0.33770612, -0.12913908, -0.1806995, -0.08245...</td>\n",
       "      <td>0.33793184, -0.41495252, -0.010535245, -0.4272...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5636469, -0.18888175, 0.057964522, -0.309588...</td>\n",
       "      <td>-0.2408412, -0.23645157, -0.14024694, 0.156071...</td>\n",
       "      <td>-0.10034606, -0.46013853, -0.16565657, -0.1625...</td>\n",
       "      <td>-0.08547448, -0.29826584, -0.14741431, -0.6706...</td>\n",
       "      <td>-0.2249016, -0.053476267, 0.08432953, -0.04551...</td>\n",
       "      <td>0.07270025, -0.1588778, 0.12582761, -0.1677677...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.08547448, -0.29826584, -0.14741431, -0.6706...</td>\n",
       "      <td>-0.2249016, -0.053476267, 0.08432953, -0.04551...</td>\n",
       "      <td>-0.059532832, -0.0901145, -0.049665194, -0.091...</td>\n",
       "      <td>0.03562126, 0.12509596, 0.14319207, -0.3288557...</td>\n",
       "      <td>0.27164158, 0.13193674, -0.42138663, -0.097306...</td>\n",
       "      <td>0.072927535, -0.5590427, -0.24776436, 0.344729...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.2408412, -0.23645157, -0.14024694, 0.156071...</td>\n",
       "      <td>-0.10034606, -0.46013853, -0.16565657, -0.1625...</td>\n",
       "      <td>-0.08547448, -0.29826584, -0.14741431, -0.6706...</td>\n",
       "      <td>-0.2249016, -0.053476267, 0.08432953, -0.04551...</td>\n",
       "      <td>0.5636469, -0.18888175, 0.057964522, -0.309588...</td>\n",
       "      <td>-0.16987483, -0.2249915, -0.29015827, -0.17841...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.004935925, -0.13656415, -0.23017032, -0.2976...</td>\n",
       "      <td>-0.2408412, -0.23645157, -0.14024694, 0.156071...</td>\n",
       "      <td>-0.062034734, -0.13488984, -0.052092835, -0.16...</td>\n",
       "      <td>-0.16987483, -0.2249915, -0.29015827, -0.17841...</td>\n",
       "      <td>-0.10034606, -0.46013853, -0.16565657, -0.1625...</td>\n",
       "      <td>-0.21884118, -0.2691241, -0.1506517, -0.258438...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>112</td>\n",
       "      <td>0.34240687, -0.7799633, -0.07325146, 0.1758222...</td>\n",
       "      <td>0.2314727, -0.34008136, -0.29488656, 0.0500874...</td>\n",
       "      <td>-0.012104189, -0.42934826, -0.043598104, -0.16...</td>\n",
       "      <td>-0.093848124, -0.4444801, 0.17228708, -0.05815...</td>\n",
       "      <td>0.050761756, -0.46189064, -0.2532838, -0.24484...</td>\n",
       "      <td>0.28268155, -0.38978544, 0.19297943, -0.105613...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>113</td>\n",
       "      <td>0.3019928, -0.26045924, 0.015733648, 0.2703662...</td>\n",
       "      <td>-0.18584548, -0.1925051, 0.10625949, -0.206512...</td>\n",
       "      <td>0.011111926, -0.12589762, -0.3675967, 0.210303...</td>\n",
       "      <td>-0.11889708, -0.22299579, -0.026865011, 0.0308...</td>\n",
       "      <td>0.09591463, -0.48508278, -0.06891152, 0.276375...</td>\n",
       "      <td>0.1566172, -0.20473818, -0.035458744, -0.19221...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>114</td>\n",
       "      <td>-0.077284046, -0.22232834, 0.08215106, -0.0576...</td>\n",
       "      <td>-0.039106183, -0.6523534, -0.105695486, -0.145...</td>\n",
       "      <td>-0.17606132, -0.23837931, 0.0044720406, -0.160...</td>\n",
       "      <td>-0.0618737, -0.7343093, -0.32571483, -0.132904...</td>\n",
       "      <td>-0.13264681, -0.3496549, 0.3373038, -0.2372643...</td>\n",
       "      <td>-0.17120218, -0.26937917, 0.13105515, -0.21617...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>115</td>\n",
       "      <td>0.09196025, -0.14238328, -0.15650213, 0.016880...</td>\n",
       "      <td>-0.25230637, -0.20939383, 0.1711297, 0.0969001...</td>\n",
       "      <td>0.27576885, 0.044581182, -0.32616004, -0.23116...</td>\n",
       "      <td>0.050242823, -0.49941212, 0.08789326, -0.34341...</td>\n",
       "      <td>-0.1013802, -0.37508678, 0.20165949, -0.107570...</td>\n",
       "      <td>0.31933656, -0.32946482, 0.11305168, -0.188344...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>116</td>\n",
       "      <td>-0.15108453, 0.005995904, -0.09572674, -0.2714...</td>\n",
       "      <td>-0.14696082, -0.042382833, 0.062948234, -0.115...</td>\n",
       "      <td>0.2686744, -0.26194662, -0.07545594, 0.0291606...</td>\n",
       "      <td>0.03468486, -0.2507916, -0.3768246, -0.0077461...</td>\n",
       "      <td>-0.17512134, 0.15738672, 0.20710538, -0.339654...</td>\n",
       "      <td>-0.013482762, -0.44161817, 0.23208238, -0.4207...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       K                                                 S1  \\\n",
       "0      1  -0.08547448, -0.29826584, -0.14741431, -0.6706...   \n",
       "1      2  0.5636469, -0.18888175, 0.057964522, -0.309588...   \n",
       "2      3  -0.08547448, -0.29826584, -0.14741431, -0.6706...   \n",
       "3      4  -0.2408412, -0.23645157, -0.14024694, 0.156071...   \n",
       "4      5  0.004935925, -0.13656415, -0.23017032, -0.2976...   \n",
       "..   ...                                                ...   \n",
       "111  112  0.34240687, -0.7799633, -0.07325146, 0.1758222...   \n",
       "112  113  0.3019928, -0.26045924, 0.015733648, 0.2703662...   \n",
       "113  114  -0.077284046, -0.22232834, 0.08215106, -0.0576...   \n",
       "114  115  0.09196025, -0.14238328, -0.15650213, 0.016880...   \n",
       "115  116  -0.15108453, 0.005995904, -0.09572674, -0.2714...   \n",
       "\n",
       "                                                    S2  \\\n",
       "0    -0.2249016, -0.053476267, 0.08432953, -0.04551...   \n",
       "1    -0.2408412, -0.23645157, -0.14024694, 0.156071...   \n",
       "2    -0.2249016, -0.053476267, 0.08432953, -0.04551...   \n",
       "3    -0.10034606, -0.46013853, -0.16565657, -0.1625...   \n",
       "4    -0.2408412, -0.23645157, -0.14024694, 0.156071...   \n",
       "..                                                 ...   \n",
       "111  0.2314727, -0.34008136, -0.29488656, 0.0500874...   \n",
       "112  -0.18584548, -0.1925051, 0.10625949, -0.206512...   \n",
       "113  -0.039106183, -0.6523534, -0.105695486, -0.145...   \n",
       "114  -0.25230637, -0.20939383, 0.1711297, 0.0969001...   \n",
       "115  -0.14696082, -0.042382833, 0.062948234, -0.115...   \n",
       "\n",
       "                                                    S3  \\\n",
       "0    0.20120747, -0.40818706, 0.06754328, -0.208118...   \n",
       "1    -0.10034606, -0.46013853, -0.16565657, -0.1625...   \n",
       "2    -0.059532832, -0.0901145, -0.049665194, -0.091...   \n",
       "3    -0.08547448, -0.29826584, -0.14741431, -0.6706...   \n",
       "4    -0.062034734, -0.13488984, -0.052092835, -0.16...   \n",
       "..                                                 ...   \n",
       "111  -0.012104189, -0.42934826, -0.043598104, -0.16...   \n",
       "112  0.011111926, -0.12589762, -0.3675967, 0.210303...   \n",
       "113  -0.17606132, -0.23837931, 0.0044720406, -0.160...   \n",
       "114  0.27576885, 0.044581182, -0.32616004, -0.23116...   \n",
       "115  0.2686744, -0.26194662, -0.07545594, 0.0291606...   \n",
       "\n",
       "                                                    S4  \\\n",
       "0    -0.04608272, -0.38059863, -0.3007064, -0.10318...   \n",
       "1    -0.08547448, -0.29826584, -0.14741431, -0.6706...   \n",
       "2    0.03562126, 0.12509596, 0.14319207, -0.3288557...   \n",
       "3    -0.2249016, -0.053476267, 0.08432953, -0.04551...   \n",
       "4    -0.16987483, -0.2249915, -0.29015827, -0.17841...   \n",
       "..                                                 ...   \n",
       "111  -0.093848124, -0.4444801, 0.17228708, -0.05815...   \n",
       "112  -0.11889708, -0.22299579, -0.026865011, 0.0308...   \n",
       "113  -0.0618737, -0.7343093, -0.32571483, -0.132904...   \n",
       "114  0.050242823, -0.49941212, 0.08789326, -0.34341...   \n",
       "115  0.03468486, -0.2507916, -0.3768246, -0.0077461...   \n",
       "\n",
       "                                                    S5  \\\n",
       "0    -0.33770612, -0.12913908, -0.1806995, -0.08245...   \n",
       "1    -0.2249016, -0.053476267, 0.08432953, -0.04551...   \n",
       "2    0.27164158, 0.13193674, -0.42138663, -0.097306...   \n",
       "3    0.5636469, -0.18888175, 0.057964522, -0.309588...   \n",
       "4    -0.10034606, -0.46013853, -0.16565657, -0.1625...   \n",
       "..                                                 ...   \n",
       "111  0.050761756, -0.46189064, -0.2532838, -0.24484...   \n",
       "112  0.09591463, -0.48508278, -0.06891152, 0.276375...   \n",
       "113  -0.13264681, -0.3496549, 0.3373038, -0.2372643...   \n",
       "114  -0.1013802, -0.37508678, 0.20165949, -0.107570...   \n",
       "115  -0.17512134, 0.15738672, 0.20710538, -0.339654...   \n",
       "\n",
       "                                                    S6  \n",
       "0    0.33793184, -0.41495252, -0.010535245, -0.4272...  \n",
       "1    0.07270025, -0.1588778, 0.12582761, -0.1677677...  \n",
       "2    0.072927535, -0.5590427, -0.24776436, 0.344729...  \n",
       "3    -0.16987483, -0.2249915, -0.29015827, -0.17841...  \n",
       "4    -0.21884118, -0.2691241, -0.1506517, -0.258438...  \n",
       "..                                                 ...  \n",
       "111  0.28268155, -0.38978544, 0.19297943, -0.105613...  \n",
       "112  0.1566172, -0.20473818, -0.035458744, -0.19221...  \n",
       "113  -0.17120218, -0.26937917, 0.13105515, -0.21617...  \n",
       "114  0.31933656, -0.32946482, 0.11305168, -0.188344...  \n",
       "115  -0.013482762, -0.44161817, 0.23208238, -0.4207...  \n",
       "\n",
       "[116 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attrition_data = 'cbd.csv'\n",
    "df_attrition = pd.read_csv(attrition_data)\n",
    "target_column = 'word'\n",
    "selected_columns = ['K', 'S1', 'S2', 'S3', \\\n",
    "                    'S4', 'S5','S6']\n",
    "\n",
    "df_attrition = df_attrition.loc[:, selected_columns]\n",
    "df_attrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphLoader:\n",
    "    def __init__(self):\n",
    "        self.graph = None\n",
    "        self.title = None\n",
    "        \n",
    "    def build_graph(self, \n",
    "                    dataframe: pd.DataFrame, \n",
    "                    columns: List, \n",
    "                    edge_list: List,\n",
    "                    verbose: bool = True,\n",
    "                    title: str = 'Unnamed'):\n",
    "        self.title = title\n",
    "        t0 = time()\n",
    "        self.graph = nx.Graph(name = self.title)\n",
    "\n",
    "        # Add Nodes to the graph.\n",
    "        for column in columns:\n",
    "            self.graph.add_nodes_from(dataframe[column].values, label=column)\n",
    "\n",
    "        # Add remaining columns as Node attributes. Optional\n",
    "        remaining = dataframe.columns.difference(columns)\n",
    "        for node, data in self.graph.nodes(data=True):\n",
    "            if data[\"label\"] == \"K\":\n",
    "                self.graph.nodes[node][\"K\"] = dataframe.loc[dataframe[\"K\"] == int(node), remaining].squeeze().to_dict()\n",
    "\n",
    "        # Add Edges.\n",
    "        for _, row in dataframe.loc[:, columns].iterrows():\n",
    "            for edge in edge_list:\n",
    "                self.graph.add_edge(row[edge[0]], row[edge[1]])\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"FINISHED in {np.round(time() - t0, 3)} seconds.\")\n",
    "            print(nx.info(self.graph))\n",
    "        \n",
    "        return self.graph\n",
    "\n",
    "    def draw_graph(self, graph: nx.Graph, node_colors: dict, node: str = None, radius: int = 1) -> None:\n",
    "        def assign_colors(graph: nx.Graph) -> List:\n",
    "            # Assign Colors to nodes\n",
    "            colors = []\n",
    "            for n, data in graph.nodes(data=True):\n",
    "                node = data[\"label\"]\n",
    "                colors.append(node_colors.get(node, \"white\"))\n",
    "            return colors\n",
    "\n",
    "        f = plt.figure(figsize = (20,12), facecolor=\"darkgray\")\n",
    "        ax = f.add_subplot()\n",
    "\n",
    "        if not node:    \n",
    "            plt.title(self.title)\n",
    "        else:\n",
    "            plt.title(f\"Ego Graph around the node {node}, (radius={radius})\")\n",
    "            graph = nx.ego_graph(graph, node, radius = radius)\n",
    "        \n",
    "        colors = assign_colors(graph)\n",
    "        nx.draw_networkx(graph, node_size = 300, node_color = colors, with_labels = False)\n",
    "        # Add an empty plot to set custom legends\n",
    "        from matplotlib.lines import Line2D\n",
    "        ax.scatter([],[])\n",
    "        legend_elements = [\n",
    "            Line2D([0], [0], marker='o', color='w', label='K', markerfacecolor = node_colors['K'], markersize=15),\n",
    "            Line2D([0], [0], marker='o', color='w', label='S1', markerfacecolor = node_colors['S1'], markersize=10),\n",
    "            Line2D([0], [0], marker='o', color='w', label='S2', markerfacecolor = node_colors['S2'], markersize=10),\n",
    "            Line2D([0], [0], marker='o', color='w', label='S3', markerfacecolor = node_colors['S3'], markersize=10),\n",
    "            Line2D([0], [0], marker='o', color='w', label='S4', markerfacecolor = node_colors['S4'], markersize=10),\n",
    "            Line2D([0], [0], marker='o', color='w', label='S5', markerfacecolor = node_colors['S5'], markersize=10),\n",
    "            Line2D([0], [0], marker='o', color='w', label='S6', markerfacecolor = node_colors['S6'], markersize=10),\n",
    "\n",
    "        ]\n",
    "        ax.legend(handles=legend_elements, loc='best')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = selected_columns[:] # Do not select Attrition as a feature node\n",
    "edges = [(\"K\",\"S1\"),\n",
    "         (\"K\",\"S2\"),\n",
    "         (\"K\",\"S3\"),\n",
    "         (\"K\",\"S4\"),\n",
    "         (\"K\",\"S5\"),\n",
    "         (\"K\",\"S6\")]\n",
    "\n",
    "node_colors = { # freestyle, update any color.\n",
    "    \"K\": \"dodgerblue\", \n",
    "    \"S1\":\"lightgreen\", \n",
    "    \"S2\":\"tan\", \n",
    "    \"S3\":\"salmon\",\n",
    "    \"S4\":\"darkcyan\",\n",
    "    \"S5\":\"lightblue\",\n",
    "    \"S6\":\"yellow\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISHED in 0.094 seconds.\n",
      "Graph named 'Multilingual Out of Vocabulary Terms relationship' with 502 nodes and 693 edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp/ipykernel_891088/2062787566.py:71: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "graph_loader = GraphLoader()\n",
    "demo_graph = graph_loader.build_graph(\n",
    "            dataframe = df_attrition.loc[:, selected_columns[:]],\n",
    "            columns = nodes, \n",
    "            edge_list = edges,\n",
    "            verbose = True,\n",
    "            title = 'Multilingual Out of Vocabulary Terms relationship'\n",
    "        )\n",
    "# graph_loader.draw_graph(demo_graph, node_colors, node = 5, radius = 2) # show only the nodes that are at a distance of 2 edges from the employee 5.\n",
    "graph_loader.draw_graph(demo_graph, node_colors) # Show the whole graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CWD = Path().cwd()\n",
    "EMBEDDINGS_DIR = CWD / 'embeddings'\n",
    "EMBEDDINGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SEED = 12\n",
    "\n",
    "class VectorizerConfig:\n",
    "    dimensions = 300\n",
    "    walk_length = 30\n",
    "    num_walks = 50\n",
    "    window = 10\n",
    "    min_count = 1\n",
    "    batch_words = 100\n",
    "\n",
    "class NodeEmbedding:\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.vectorizer = None\n",
    "        self.model = None\n",
    "        \n",
    "    def generate_random_walks(self, graph: nx.Graph, **params) -> None:\n",
    "        self.vectorizer = Node2Vec(graph, **params)\n",
    "        # return self.vectorizer\n",
    "\n",
    "    def fit(self, **params) -> gensim.models.Word2Vec:\n",
    "        if self.vectorizer is None:\n",
    "            raise Exception(\"No random walks. Generate Random walks by calling generate_random_walks() method first.\")\n",
    "        self.model = self.vectorizer.fit(**params)\n",
    "        \n",
    "        return self.model\n",
    "    def save_model(self, model: gensim.models.Word2Vec, save_to: Path = EMBEDDINGS_DIR, prefix: str = None) -> None:\n",
    "        d = VectorizerConfig.dimensions\n",
    "        w = VectorizerConfig.walk_length\n",
    "        n = VectorizerConfig.num_walks\n",
    "        embeddings_filename = f\"{prefix}_embeddings_{d}_{w}_{n}.txt\"\n",
    "        model_filename = f\"{prefix}_model_{d}_{w}_{n}.pkl\"\n",
    "        # Save only the embeddings in a txt file.\n",
    "        self.model.wv.save_word2vec_format(str(EMBEDDINGS_DIR/embeddings_filename))\n",
    "        # Save the entire model.\n",
    "        self.model.save(str(EMBEDDINGS_DIR/model_filename))\n",
    "        print(f\"Model and embeddings saved to: {str(EMBEDDINGS_DIR/model_filename)}\")\n",
    "    def load_model(self, model_filename: str = None, load_from: Path = EMBEDDINGS_DIR) -> gensim.models.Word2Vec:\n",
    "        if Path(EMBEDDINGS_DIR / model_filename).exists():\n",
    "            print(\"Loaded Model: \", model_filename)\n",
    "            with Path(EMBEDDINGS_DIR / model_filename).open(mode=\"r+b\") as file:\n",
    "                self.model = pickle.load(file)\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"NOT found: {EMBEDDINGS_DIR / model_filename}\")\n",
    "        \n",
    "        return self.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "embedder = NodeEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 502/502 [00:00<00:00, 11675.46it/s]\n"
     ]
    }
   ],
   "source": [
    "embedder.generate_random_walks(\n",
    "    demo_graph,\n",
    "    dimensions = VectorizerConfig.dimensions,\n",
    "    walk_length = VectorizerConfig.walk_length,\n",
    "    num_walks = VectorizerConfig.num_walks,\n",
    "    workers = multiprocessing.cpu_count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = embedder.fit(\n",
    "    window = VectorizerConfig.window,\n",
    "    min_count = VectorizerConfig.min_count,\n",
    "    batch_words = VectorizerConfig.batch_words\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and embeddings saved to: c:\\Users\\Administrator\\Dropbox\\毕业论文\\实验\\embeddings\\K_model_300_30_50.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embedder.save_model(model, save_to = EMBEDDINGS_DIR, prefix = \"K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model:  K_model_128_30_50.pkl\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from time import time\n",
    "from typing import List, Dict, Set, Tuple\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import gensim\n",
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "from pandas_profiling import ProfileReport\n",
    "attrition = 'test.csv'\n",
    "df_ac = pd.read_csv(attrition,encoding='utf-8')\n",
    "embedder = NodeEmbedding()\n",
    "model2 = embedder.load_model(r\"K_model_128_30_50.pkl\", load_from = EMBEDDINGS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'embeddings/K_embeddings_128_30_50.txt', 'r',encoding='UTF-8') as embeddings_file:\n",
    "    embeddings = embeddings_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['502 128\\n']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is requred since embeddings are out of order with the target. They were not matched correctly.\n",
    "def align_features_and_target(df: pd.DataFrame, embeddings_file: str = None):\n",
    "    vectors = []\n",
    "    with Path(EMBEDDINGS_DIR / embeddings_file).open(mode=\"r\",encoding='UTF-8') as file:\n",
    "        results = file.readlines()\n",
    "        for person in df[\"K\"].values:\n",
    "            for line in results[1:]:\n",
    "                if line.split()[0] == str(person):\n",
    "                    vectors.append(line.split()[1:])\n",
    "    \n",
    "    return np.array(vectors).astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "target_column = 'word'\n",
    "selected_columns = ['K', 'S1', 'S2', 'S3', \\\n",
    "                    'S4', 'S5','S6']\n",
    "attrition_data = 'cbd.csv'\n",
    "df_attrition = pd.read_csv(attrition_data)\n",
    "df_attrition = df_attrition.loc[:, selected_columns]\n",
    "embeddings_filename = r\"K_embeddings_128_30_50.txt\"\n",
    "feature_vectors = align_features_and_target(df_attrition, embeddings_file = embeddings_filename)\n",
    "attrition_data = 'cbd.csv'\n",
    "df_attrition = pd.read_csv(attrition_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'백신패스'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ac.loc[df_ac['K']==1]['word'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" +' Similarity:'+str(b[d][1]) \""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def func(*kargs): return kargs\n",
    "def rec(S,model):\n",
    "    print('~'*20)\n",
    "    s=S\n",
    "    a=model.wv.similar_by_word(str(s))\n",
    "    b=[]\n",
    "    \n",
    "    for i in range(len(a)):\n",
    "        try:\n",
    "            b.append([int(a[i][0]),a[i][1]])\n",
    "        except ValueError:\n",
    "            p=1\n",
    "    c=[]\n",
    "    for d in range(len(b)):\n",
    "        c.append(str(df_ac.loc[df_ac['K']==b[d][0]]['word'].values[0]))\n",
    "    print(str(s)+'.'+df_ac.loc[df_ac['K']==s]['word'].values[0]+str(c))\n",
    "\"\"\" +' Similarity:'+str(b[d][1]) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~\n",
      "1.백신패스['健康码', 'ワクチンパスポト']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "2.위드코로나['ウィズコロナ', '段階日常回復']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "3.접종완료자['完成接种人员', 'ワクチンパスポト', 'ウィズコロナ']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "4.ウィズコロナ['위드코로나', '段階日常回復']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "5.段階日常回復['ウィズコロナ', '위드코로나']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "6.ワクチンパスポト['健康码', '백신패스']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "7.内卷['노오력']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "8.노오력['内卷', '쪄죽따']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "9.道路族['ヒンナムノー']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "10.無策政府['가학방역']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "11.가학방역['無策政府', '웃안웃']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "12.原生家庭['親ガチャ']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "13.親ガチャ['原生家庭']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "14.자택치료['居家', '自宅療養']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "15.自宅療養['居家', '자택치료']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "16.居家['自宅療養', '자택치료']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "17.健康码['백신패스', 'ワクチンパスポト']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "18.数媒土著['MZ세대', 'Z世代']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "19.Z世代['数媒土著', 'MZ세대']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "20.MZ세대['数媒土著', 'Z世代']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "21.관둠['静かな退職', '躺平']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "22.静かな退職['관둠', '躺平']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "23.躺平['静かな退職', '관둠']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "24.完成接种人员['접종완료자', 'ウィズコロナ']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "25.미접종자['花の道', '隔离经济']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "26.オミクロン['奥密克戎毒株', '段階日常回復', '完成接种人员']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "27.奥密克戎毒株['オミクロン']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "28.走花路['花の道', '꽃길']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "29.花の道['走花路', '꽃길']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "30.꽃길['走花路', '花の道']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "31.轩岚诺['힌남노']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "32.ヒンナムノー['힌남노', '道路族']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "33.힌남노['ヒンナムノー', '轩岚诺']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "34.捂脸笑['웃안웃', '黙トレ']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "35.웃안웃['捂脸笑', '가학방역']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "36.吃播['モッパン', '먹방']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "37.먹방['モッパン', '吃播']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "38.モッパン['吃播', '먹방']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "39.퐁퐁남['恐妻家', '妻管严']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "40.妻管严['恐妻家', '퐁퐁남']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "41.恐妻家['퐁퐁남', '妻管严']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "42.マザコン男['마마보이', '妈宝男']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "43.妈宝男['마마보이', 'マザコン男']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "44.마마보이['妈宝男', 'マザコン男']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "45.计划人生['人生設計', '갓생']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "46.갓생['人生設計']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "47.人生設計['计划人生', '갓생']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "48.보복소비['报复性消费', '報復消費']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "49.报复性消费['報復消費', '보복소비']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "50.報復消費['报复性消费', '보복소비']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "51.포스트코로나['ポストコロナ', '后疫情时代']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "52.后疫情时代['ポストコロナ', '포스트코로나']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "53.ポストコロナ['后疫情时代', '포스트코로나']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "54.큐코노미['隔离经济']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "55.隔离经济['큐코노미']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "56.ジェンダー平等['性别平等', '젠더평등']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "57.性别平等['ジェンダー平等', '젠더평등']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "58.젠더평등['ジェンダー平等']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "59.인파['人流']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "60.人流['인파']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "61.메타버스['メタバース', '元宇宙']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "62.メタバース['메타버스', '元宇宙']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "63.元宇宙['메타버스', 'メタバース']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "64.インフルエンザ-['网红', '키보드전사', '荒らし']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "65.网红['インフルエンザ-', '荒らし', '키보드전사']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "66.맘충['妈虫', 'ママ虫']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "67.妈虫['맘충', 'ママ虫']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "68.ママ虫['맘충', '妈虫']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "69.비담['颜值担当', 'ビジュアル担当']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "70.颜值担当['ビジュアル担当', '비담']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "71.ビジュアル担当['颜值担当', '비담']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "72.스몸비['歩きスマホ', '低头族']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "73.歩きスマホ['스몸비', '低头族']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "74.지독한놈['是个狼人']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "75.是个狼人['지독한놈']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "76.냥집사['铲屎官', '愛猫家']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "77.铲屎官['냥집사', '愛猫家']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "78.愛猫家['냥집사', '铲屎官']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "79.刷屏['マルチ', '键盘侠', '荒らし']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "80.マルチ['刷屏', '键盘侠']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "81.荒らし['键盘侠', '키보드전사']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "82.键盘侠['荒らし', '키보드전사']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "83.키보드전사['荒らし', '键盘侠']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "84.废柴老公['ダメダン', '먹방']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "85.ダメダン['废柴老公', '隔离经济']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "86.YYDS['神推し', '꽃길', '愛猫家']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "87.神推し['YYDS', '愛猫家']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "88.低头族['歩きスマホ', '스몸비']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "89.식집사['재택근무']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "90.만잘부['老铁']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "91.网课大学['줌유니버시티', '居家办公']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "92.줌유니버시티['网课大学', 'ウェビナー', '居家办公']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "93.在宅ワーク['在宅勤務', '居家办公', '재택근무']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "94.재택근무['在宅勤務', '居家办公', '在宅ワーク']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "95.居家办公['在宅ワーク', '在宅勤務', '재택근무']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "96.在宅勤務['在宅ワーク', '재택근무', '居家办公']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "97.豆腐メンタル['쿠크', '玻璃心']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "98.玻璃心['쿠크', '豆腐メンタル']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "99.쿠크['豆腐メンタル', '玻璃心']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "100.伸手党['教えてチャン', '핑프']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "101.教えてチャン['伸手党', '핑프']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "102.핑프['伸手党', '教えてチャン']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "103.팝콘각['吃瓜']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "104.吃瓜['팝콘각']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "105.面食い['颜控']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "106.颜控['面食い', '低头族']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "107.丧偶式育儿['독박육아', 'ウンオペ']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "108.독박육아['丧偶式育儿', 'ウンオペ']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "109.ウンオペ['독박육아']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "110.老铁['만잘부']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "111.后浪['Z世代', '数媒土著']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "112.SBN['老铁']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "113.黙トレ['捂脸笑', '웃안웃']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "114.ウェビナー['居家办公', '재택근무']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "115.당모치['親ガチャ', '面食い']\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "116.쪄죽따[]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,117):\n",
    "    rec(i,model2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 4, 7, 11)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1,2,4,7,11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7082757353782654"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.wv.distance('1','11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nbTranslate": {
   "displayLangs": [
    "cn",
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "cn",
   "useGoogleTranslate": true
  },
  "vscode": {
   "interpreter": {
    "hash": "e0144baad0ecee903f108a3e46e51ceadd7da3fc904cfa79747d813b61464b4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
